import json
import re
import numpy as np
from collections import Counter

#used to separate email received into individual words 
WORD_LIST = re.compile(r"[a-z0-9]+") 


#function that takes in a string and returns a list of strings
def preprocess_text(text: str) -> list[str]:
    #lowercase the all the words and then tokenize them
    tokens = WORD_LIST.findall(text.lower())
    return tokens

def load_vocab_idf(path: str):
    #opens json file and converts it to python object
    with open(path, "r", encoding="utf-8") as file:
        obj = json.load(f)

    #checks what kind of json file we are dealing with and acts accordingly
    if "vocabulary" in obj and "idf" in obj:
        vocab = obj["vocabulary"]
        idf = np.asarray(obj["idf"], dtype=np.float32)
    else:
        vocab = obj
        idf = np.ones(len(vocab), dtype=np.float32)

    return vocab, idf
    

def text_to_tfidf(text: str, vocab: dict[str,int], idf: np.ndarray) -> np.ndarray:
    tokens = preprocess_text(text)
    counts = Counter(t for t in tokens if t in vocab)

    #basically turns dictionary into vector
    vocab_len = len(vocab)
    vec = np.zeros(vocab_len, dtype=np.float32)
    for term, c in counts.item():
        ind = vocab[term]
        vec[ind] = c
    
    vec *= idf  #TF * IDF

    #normalizes the values in the vector to make them all have a length of 1
    norm = np.linalg.norm(vec)
    if norm > 0:
        vec /= norm
    
    return vec
